# LLM_Custom
this repo will share a simple rule handler LLM  for prompt requests within an enclosed token inside the codebase of the LLM model. 
The following dependencies are required for library files to enable the user to run LLM smoothly. 
Remember the LLM given are not trained to be ready to receive large requests that are out boundary of given data sets. 
Therefore, to ensure the program works well, we have included all answers inside the code base on this file enhanced_assistant.py 
The rest of the dependencies will be added soon. 
!!! Still Under Work !!!   

